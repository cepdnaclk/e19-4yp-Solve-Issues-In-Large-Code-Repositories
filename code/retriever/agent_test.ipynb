{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_line_numbers(input_path, output_path=None):\n",
    "    with open(input_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    numbered_lines = [f\"{i+1:4}: {line}\" for i, line in enumerate(lines)]\n",
    "\n",
    "   \n",
    "    with open(output_path, 'w') as file:\n",
    "        file.writelines(numbered_lines)\n",
    "    \n",
    "\n",
    "add_line_numbers(\"commit.py\", \"numbered_output.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, Dict\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def insert_code_at_line(\n",
    "    file_path: Annotated[str, \"Path to the Python file to insert code into.\"],\n",
    "    input_dict: Annotated[\n",
    "        Dict[str, Annotated[object, \"Contains 'start' (int) and 'code' (list of strings).\"]],\n",
    "        \"Dictionary with 'start' (1-based line index) and 'code' (lines to insert).\"\n",
    "    ]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Inserts a list of code lines into a file at a specified line number.\n",
    "\n",
    "    The inserted block is automatically wrapped with:\n",
    "        - '# Added by AI' at the beginning\n",
    "        - '# !!!' at the end\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the file being modified.\n",
    "        input_dict (dict): A dictionary with:\n",
    "            - 'start' (int): 1-based line number where code is inserted.\n",
    "            - 'code' (List[str]): Code lines to insert.\n",
    "\n",
    "    Returns:\n",
    "        str: Status message indicating where the code was inserted.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start = input_dict[\"start\"]\n",
    "        new_code = input_dict[\"code\"]\n",
    "        if not isinstance(start, int) or not isinstance(new_code, list):\n",
    "            return \"Invalid input_dict format. 'start' should be int, 'code' should be a list of strings.\"\n",
    "    except (KeyError, TypeError):\n",
    "        return \"Error: input_dict must contain keys 'start' (int) and 'code' (list of strings).\"\n",
    "\n",
    "    new_code = [\"# Added by AI\"] + new_code + [\"# !!!\"]\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: File not found - {file_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {e}\"\n",
    "\n",
    "    if start > len(lines):\n",
    "        lines.extend(['\\n'] * (start - len(lines)))\n",
    "\n",
    "    for i, line in enumerate(new_code):\n",
    "        lines.insert(start - 1 + i, line + '\\n')\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.writelines(lines)\n",
    "    except Exception as e:\n",
    "        return f\"Error writing to file: {e}\"\n",
    "\n",
    "    return f\"Inserted code at line {start} in {file_path}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "\n",
    "@tool\n",
    "def delete_lines(\n",
    "    file_path: Annotated[str, \"Path to the file from which lines will be deleted.\"],\n",
    "    start_line: Annotated[int, \"The starting line number (1-based, inclusive).\"],\n",
    "    end_line: Annotated[int, \"The ending line number (1-based, exclusive).\"]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Deletes a range of lines from a file, specified by line numbers.\n",
    "\n",
    "    The function modifies the file in-place, removing lines from start_line (inclusive)\n",
    "    up to end_line (exclusive). Line numbers are 1-based.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the file to edit.\n",
    "        start_line (int): 1-based index of the first line to delete.\n",
    "        end_line (int): 1-based index of the line after the last one to delete.\n",
    "\n",
    "    Returns:\n",
    "        str: A message indicating the outcome of the operation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: File not found - {file_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {e}\"\n",
    "\n",
    "    start_idx = max(start_line - 1, 0)\n",
    "    end_idx = min(end_line, len(lines))\n",
    "\n",
    "    if start_idx >= end_idx:\n",
    "        return \"Invalid range: no lines deleted.\"\n",
    "\n",
    "    del lines[start_idx:end_idx]\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.writelines(lines)\n",
    "    except Exception as e:\n",
    "        return f\"Error writing to file: {e}\"\n",
    "\n",
    "    return f\"Deleted lines {start_line} to {end_line - 1} from {file_path}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "@tool\n",
    "def generate_code_skeleton(\n",
    "    file_path: Annotated[str, \"Path to the Python file whose skeleton is to be extracted.\"]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Extracts a readable skeleton from a Python source file by identifying:\n",
    "      - Top-level imports\n",
    "      - Class definitions\n",
    "      - Function definitions (including async functions)\n",
    "      - AI-injected blocks demarcated by '# Added by AI' and ending at '# !!!'\n",
    "\n",
    "    Returns a string containing these elements, each prefixed with their original line numbers.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the Python source file.\n",
    "\n",
    "    Returns:\n",
    "        str: A multi-line string showing the skeleton of the file with line numbers.\n",
    "    \"\"\"\n",
    "    skeleton_lines = []\n",
    "    inside_ai_block = False\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: File not found - {file_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error while reading file: {e}\"\n",
    "\n",
    "    for idx, line in enumerate(lines, start=1):\n",
    "        stripped = line.strip()\n",
    "\n",
    "        # Basic structure: imports, class, def\n",
    "        if (\n",
    "            stripped.startswith(\"import\") or\n",
    "            stripped.startswith(\"from\") or\n",
    "            stripped.startswith(\"class \") or\n",
    "            re.match(r\"(async\\s+)?def\\s+\\w+\\s*\\(\", stripped)\n",
    "        ):\n",
    "            skeleton_lines.append(f\"{idx:4}: {line.rstrip()}\")\n",
    "\n",
    "        # Detect AI-generated blocks\n",
    "        if \"# Added by AI\" in stripped:\n",
    "            inside_ai_block = True\n",
    "            skeleton_lines.append(f\"{idx:4}: {line.rstrip()}\")\n",
    "            continue\n",
    "\n",
    "        if inside_ai_block:\n",
    "            skeleton_lines.append(f\"{idx:4}: {line.rstrip()}\")\n",
    "            if \"# !!!\" in stripped:\n",
    "                inside_ai_block = False\n",
    "\n",
    "    return \"\\n\".join(skeleton_lines) if skeleton_lines else \"No skeleton elements found.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10: # Added by AI  11: def foo():  11: def foo():  12:     print('Hello')  13:     return  14: # !!!  16: import git  17: import sys  18: import networkx as nx  19: import pickle  20: import re  21: import os  22: from utils import utils  23: from utils.embed_skeleton import get_skeleton  24: import ast  25: import faiss  26: from dotenv import load_dotenv  27: from langchain.embeddings import OpenAIEmbeddings  28: from langchain_community.docstore.in_memory import InMemoryDocstore  29: from langchain_community.vectorstores import FAISS  30: from langchain_core.documents import Document  33: def neighbors_by_relation(G, node, relation_type):  45: def find_function_or_class(path, name, graph):  52: def filter_import_lines(code_lines):  58:     import_pattern = re.compile(r'^\\s*(import\\s+\\w|from\\s+\\w+(\\.\\w+)*\\s+import\\s+)')  61: def extract_imports(base, file_path, graph):  67:     imports = set()  82:                         imports.add(base + node.module.replace(\".\", \"/\")+ \"/\" + alias.name+\".py\")  85:                         imports.add(base +node.module.replace(\".\", \"/\") +\".py\")  89:                             imports.add(found_name)  92: def update_class_functions_file(files, graph): 108: def load_graph(pickle_path): 114: def save_graph(graph, pickle_path): 120: def checkout_commit(repo_path, base_commit): 127: def insert_edge(G, u, v, relation=None, node_type_v=None, node_type_u=None): 139: def delete_node_and_edges(G, node): 146: def remove_isolated_nodes(G): 151: def update(repo_path, latest_commit): 244:         import_files = extract_imports(repo_path, file_path, graph)\n"
     ]
    }
   ],
   "source": [
    "print(generate_code_skeleton(\"commit.py\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def view_code_block(\n",
    "    file_path: Annotated[str, \"Path to the file to view a block from.\"],\n",
    "    start_line: Annotated[int, \"1-based starting line number (inclusive).\"],\n",
    "    end_line: Annotated[int, \"1-based ending line number (inclusive).\"]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Returns a specific block of lines from a file, between start_line and end_line (both inclusive).\n",
    "\n",
    "    This is useful for inspecting a portion of code without loading the entire file content,\n",
    "    especially within code manipulation agents.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file.\n",
    "        start_line (int): 1-based line number to start viewing from (inclusive).\n",
    "        end_line (int): 1-based line number to end viewing at (inclusive).\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted code block as a string, or an error message if inputs are invalid.\n",
    "    \"\"\"\n",
    "    if start_line > end_line:\n",
    "        return \"Error: start_line must be less than or equal to end_line.\"\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: File not found - {file_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {e}\"\n",
    "\n",
    "    if start_line < 1 or end_line > len(lines):\n",
    "        return f\"Error: Line numbers out of bounds (file has {len(lines)} lines).\"\n",
    "\n",
    "    block = lines[start_line - 1:end_line]\n",
    "    return ''.join(block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Any, List, Dict\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of an agent, including its name and the current file being edited.\n",
    "    \"\"\"\n",
    "    current_file: str\n",
    "    candidates: List[Dict[str, Any]]\n",
    "    instructions: str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Dict, Any\n",
    "from langgraph.graph import State\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_next_candidate(\n",
    "    state: AgentState\n",
    ") -> AgentState:\n",
    "    \n",
    "    try:\n",
    "        candidates = state.get(\"candidates\", [])\n",
    "        if not isinstance(candidates, list) or len(candidates) == 0:\n",
    "            return {\"error\": \"State must contain a non-empty 'candidates' list.\"}\n",
    "\n",
    "        top = max(candidates, key=lambda c: float(c.get(\"score\", float(\"-inf\"))))\n",
    "        return top\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Failed to select top candidate: {str(e)}\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Added by AI\n",
      "def foo():\n",
      "    print('Hello')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(extract_code_block_as_string(\"commit.py\", 10, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "from langchain.agents import tool\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1,\n",
    "    #max_retries=2,\n",
    ")\n",
    "\n",
    "dataset = load_dataset(\"lahirum/SWE_Experimental\", split=\"train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentless",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
